{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# dirname = os.path.dirname(__file__)\n",
    "# filename = os.path.join(dirname, 'dataset/foodcostpred/Data_Train.xlsx')\n",
    "training_data = pd.read_excel('dataset/Data_Train.xlsx')\n",
    "test_data = pd.read_excel('dataset/Data_Test.xlsx')\n",
    "training_data = pd.DataFrame(training_data,columns=['TITLE','RESTAURANT_ID','CUISINES', 'TIME','CITY','LOCALITY','RATING', 'VOTES','COST'])\n",
    "test_data = pd.DataFrame(test_data,columns=['TITLE','RESTAURANT_ID','CUISINES', 'TIME','CITY','LOCALITY','RATING', 'VOTES','COST'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EDA on Training Set\n",
      "\n",
      "##############################\n",
      "\n",
      "Features/Columns : \n",
      " Index(['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
      "       'RATING', 'VOTES', 'COST'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Number of Features/Columns :  9\n",
      "\n",
      "Number of Rows :  12690\n",
      "\n",
      "\n",
      "Data Types :\n",
      " TITLE            object\n",
      "RESTAURANT_ID     int64\n",
      "CUISINES         object\n",
      "TIME             object\n",
      "CITY             object\n",
      "LOCALITY         object\n",
      "RATING           object\n",
      "VOTES            object\n",
      "COST              int64\n",
      "dtype: object\n",
      "\n",
      "Contains NaN/Empty cells :  True\n",
      "\n",
      "Total empty cells by column :\n",
      " TITLE               0\n",
      "RESTAURANT_ID       0\n",
      "CUISINES            0\n",
      "TIME                0\n",
      "CITY              112\n",
      "LOCALITY           98\n",
      "RATING              2\n",
      "VOTES            1204\n",
      "COST                0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "##############################\n",
      "\n",
      "EDA on Test Set\n",
      "\n",
      "##############################\n",
      "\n",
      "Features/Columns : \n",
      " Index(['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
      "       'RATING', 'VOTES', 'COST'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Number of Features/Columns :  9\n",
      "\n",
      "Number of Rows :  4231\n",
      "\n",
      "\n",
      "Data Types :\n",
      " TITLE             object\n",
      "RESTAURANT_ID      int64\n",
      "CUISINES          object\n",
      "TIME              object\n",
      "CITY              object\n",
      "LOCALITY          object\n",
      "RATING            object\n",
      "VOTES             object\n",
      "COST             float64\n",
      "dtype: object\n",
      "\n",
      "Contains NaN/Empty cells :  True\n",
      "\n",
      "Total empty cells by column :\n",
      " TITLE               0\n",
      "RESTAURANT_ID       0\n",
      "CUISINES            0\n",
      "TIME                0\n",
      "CITY               35\n",
      "LOCALITY           30\n",
      "RATING              2\n",
      "VOTES             402\n",
      "COST             4231\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --------------CHECK FEATURES---------------\n",
    "\n",
    "#Training Set\n",
    "\n",
    "print(\"\\nEDA on Training Set\\n\")\n",
    "print(\"#\"*30)\n",
    "print(\"\\nFeatures/Columns : \\n\", training_data.columns)\n",
    "print(\"\\n\\nNumber of Features/Columns : \", len(training_data.columns))\n",
    "print(\"\\nNumber of Rows : \",len(training_data))\n",
    "print(\"\\n\\nData Types :\\n\", training_data.dtypes)\n",
    "print(\"\\nContains NaN/Empty cells : \", training_data.isnull().values.any())\n",
    "print(\"\\nTotal empty cells by column :\\n\", training_data.isnull().sum(), \"\\n\\n\")\n",
    "\n",
    "\n",
    "# Test Set\n",
    "print(\"#\"*30)\n",
    "print(\"\\nEDA on Test Set\\n\")\n",
    "print(\"#\"*30)\n",
    "print(\"\\nFeatures/Columns : \\n\",test_data.columns)\n",
    "print(\"\\n\\nNumber of Features/Columns : \",len(test_data.columns))\n",
    "print(\"\\nNumber of Rows : \",len(test_data))\n",
    "print(\"\\n\\nData Types :\\n\", test_data.dtypes)\n",
    "print(\"\\nContains NaN/Empty cells : \", test_data.isnull().values.any())\n",
    "print(\"\\nTotal empty cells by column :\\n\", test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Unique Titles :  25\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['CASUAL DINING' 'QUICK BITES' 'DESSERT PARLOR' 'CAFÃ‰' 'MICROBREWERY'\n",
      " 'BAKERY' 'NONE' 'BAR' 'PUB' 'BEVERAGE SHOP' 'FINE DINING' 'SWEET SHOP'\n",
      " 'FOOD COURT' 'LOUNGE' 'FOOD TRUCK' 'MESS' 'KIOSK' 'CLUB' 'DHABA'\n",
      " 'MEAT SHOP' 'COCKTAIL BAR' 'CONFECTIONERY' 'PAAN SHOP' 'IRANI CAFE'\n",
      " 'BHOJANALYA']\n",
      "\n",
      "\n",
      "Number of Unique CUISINES :  106\n",
      "\n",
      "\n",
      "Unique CUISINES:\n",
      " ['MALWANI' 'ASIAN' 'NORTH INDIAN' 'TIBETAN' 'DESSERTS' 'CAFE' 'BAR FOOD'\n",
      " 'SOUTH INDIAN' 'FAST FOOD' 'ARABIAN' 'MAHARASHTRIAN' 'PARSI' 'CHINESE'\n",
      " 'BAKERY' 'CONTINENTAL' 'ANDHRA' 'BIRYANI' 'ITALIAN' 'FINGER FOOD'\n",
      " 'BEVERAGES' 'AMERICAN' 'EUROPEAN' 'ICE CREAM' 'KERALA' 'SEAFOOD' 'PIZZA'\n",
      " 'MITHAI' 'ROLLS' 'THAI' 'JUICES' 'BURGER' 'HYDERABADI' 'MEDITERRANEAN'\n",
      " 'GUJARATI' 'MEXICAN' 'HEALTHY FOOD' 'SANDWICH' 'INDIAN' 'COFFEE'\n",
      " 'INDONESIAN' 'BBQ' 'BIHARI' 'LEBANESE' 'BENGALI' 'CHETTINAD' 'MUGHLAI'\n",
      " 'STREET FOOD' 'RAJASTHANI' 'PORTUGUESE' 'ORIYA' 'JAPANESE' 'ETHIOPIAN'\n",
      " 'MODERN INDIAN' 'SPANISH' 'RUSSIAN' 'MANGALOREAN' 'TURKISH' 'STEAK'\n",
      " 'KEBAB' 'WRAPS' 'MOMOS' 'NAGA' 'BURMESE' 'MALAYSIAN' 'KOREAN' 'TEA'\n",
      " 'SINDHI' 'VIETNAMESE' 'GOAN' 'FRENCH' 'RAW MEATS' 'SALAD'\n",
      " 'MIDDLE EASTERN' 'KASHMIRI' 'NORTH EASTERN' 'SRI LANKAN' 'SUSHI'\n",
      " 'TEX-MEX' 'AFGHAN' 'KONKAN' 'BUBBLE TEA' 'AFRICAN' 'GERMAN' 'DRINKS ONLY'\n",
      " 'PAAN' 'ASSAMESE' 'NEPALESE' 'HOT DOGS' 'CAFE FOOD' 'AWADHI' 'BRITISH'\n",
      " 'BOHRI' 'ARMENIAN' 'SOUTH AMERICAN' 'IRANIAN' 'LUCKNOWI'\n",
      " 'CHARCOAL CHICKEN' 'TAMIL' 'PAKISTANI' 'IRISH' 'MULTI CUISINE'\n",
      " 'ROAST CHICKEN' 'SINGAPOREAN' 'EGYPTIAN' 'BRAZILIAN' 'CANTONESE']\n",
      "\n",
      "\n",
      "Number of Unique CITY :  445\n",
      "\n",
      "\n",
      "Unique CITY:\n",
      " ['THANE' 'CHENNAI' 'MUMBAI' 'BANGALORE' 'GURGAON' 'HYDERABAD' 'KOCHI'\n",
      " 'THANE WEST' 'ANDHERI LOKHANDWALA' 'NEW DELHI' 'ANDHERI WEST'\n",
      " 'MALAD EAST' '682036' 'BANGALOR' 'NAVI MUMBAI' 'BANDRA WEST' 'DELHI'\n",
      " 'NOIDA' 'BANGALORE-560066' 'SECUNDERABAD' nan 'INDIA' 'MADHURANAGAR'\n",
      " 'CHENNAI TEYNAMPET' 'FARIDABAD' 'CHEMBUR.' 'MAHARASHTRA'\n",
      " 'OPP GURUDWARA SHAKURPUR' 'TELAGANA LAND LINE:040-48507016' 'GHAZIABAD'\n",
      " 'KARNATAKA' 'KERALA' 'EDAPPALLY' 'KADAVANTHRA' 'ERNAKULAM CIRCLE KOCHI'\n",
      " 'BENGALORE' 'NEAR RELIANCE FRESH' 'KILPAUK' 'BENGALURU' 'KOTHAGUDA'\n",
      " 'GOREGAON WEST' 'BANGLORE' 'TAMIL NADU' 'KAKKANAD' 'KOCHI ELAMKULAM'\n",
      " 'OUTER RING ROAD' 'MULUND EAST'\n",
      " 'SECUNDERABAD MAIN ROAD NEAR SIGNAL NMREC COLLEGE' 'TELANGANA'\n",
      " 'PONNURUNI KOCHI' 'GACHIBOWLI' 'SEMMANCHERI'\n",
      " '5TH MAIN TEACHERS COLONY KORAMANGALA BLOCK 1 BANGALORE 560034'\n",
      " 'MUMBAI MAHIM' 'POWAI (NEXT TO POWAI PLAZA)' 'DOMBIVALI EAST'\n",
      " 'KOCHI VYTTILA' 'KANDIVALI' 'KOCHI PALARIVATTOM' 'DEWAN RAMA ROAD'\n",
      " 'GURUGRAM' 'SECTOR 51 NOIDA' 'KALOOR' 'BESANT NAGAR'\n",
      " 'ARUMBAKKAM CHENNAI-600106.' 'ADJACENT TO COMMERCIAL STREET' 'DELHI NCR'\n",
      " 'DWARKA' '682035.' 'KALYAN WEST' 'AVADI' 'KONDAPUR' 'MEHDIPATNAM'\n",
      " 'GANDIPET' 'VELACHERY' 'PALLAVARAM' 'VIJAYA NAGAR' 'BTM LAYOUT'\n",
      " 'CHENNAI 600034.'\n",
      " 'METRO PILLAR NO 21. METTUGUDA MAIN ROAD NEAR RAILWAY DEGREE COLLEGE.'\n",
      " 'CHENNAI - 600040' 'JP NAGAR BANGALORE' 'MADHAPUR' 'ERNAKULAM' 'SARJAPUR'\n",
      " 'WHITEFIELD BANGALORE' 'KOCHI CHULLICKAL' 'KOCHI-683101'\n",
      " 'BANGALORE - 560076' 'ROHINI' 'HYDERABAD BEHIND VACS PASTRIES'\n",
      " 'HYDERABAD NEERUS EMPORIUM.' 'NAVI MUMBAI.' 'KAROL BAGH' 'PERUNGUDI'\n",
      " 'THYKOODAM' 'GREATER NOIDA' 'BANGALORE.' 'KHAIRATABAD' 'CHULLICKAL'\n",
      " 'GRANT ROAD WEST' 'HITECH CITY' 'WEST MAREDPALLY' 'MUMBAI - 400007'\n",
      " 'CHENNAI PADUR' 'CHANDER NAGAR NEW DELHI' 'NEDUMBASSERY' 'MG ROAD'\n",
      " 'NAYA NAGAR MIRA ROAD' 'PITAMPURA' 'LOWER PAREL' 'HBR LAYOUT'\n",
      " 'TELANGANA 500003' 'RAJIV GANDHI NAGAR' 'NEW DELHI.' 'MEDAVAKKAM'\n",
      " 'SATHYA NAGAR' 'P.O KOCHI' 'BEHIND RAMALAYAM TEMPLE' 'PALARIVATTOM'\n",
      " 'BRIGADE ROAD' 'MUMBAI.' 'MUMBAI ANDHERI EAST' 'VIRAR WEST' 'B-1 STAGE'\n",
      " 'CHENNAI KOVALAM' 'HYDERABAD.' 'ALUVA' 'TELANGANA 500034'\n",
      " 'IOB BANK KAMALA NAGAR' 'HSR LAYOUT' 'MARINE DRIVE' 'DLF GALLERIA'\n",
      " 'NALLATHAMBI MAIN ROAD' 'CHENNAI OPP: VASANTH & CO' 'CITYPARK'\n",
      " 'KARNATAKA 560103' 'BHAYANDAR' 'ALUVA CIRCLE' 'THAMMENAHALLI VILLAGE'\n",
      " 'SG PALYA' 'ATTAPUR.' 'NEAR SHANGRILLA BUS STOP' 'KHAR (WEST)' 'ROAD 3'\n",
      " 'KUKATPALLY' 'FARIDABD' 'TELANGANA 500032' 'DILSUKHNAGAR'\n",
      " 'MOGAPPAIR. CHENNAI' 'NEAR MUNRSHWARA TEMPLE' 'OFF BRIGADE ROAD'\n",
      " 'KHAR WEST' 'POTHERI' 'CHENNAI PERUNGUDI' 'CHENNAI THURAIPAKKAM'\n",
      " 'OMR KARAPAKKAM' 'HYDERABAD-500032' 'MUMBAI DOMBIVALI EAST'\n",
      " 'CHENNAI THOUSAND LIGHTS' 'MAHIM' 'LINGAMPALLY' 'POWAI'\n",
      " 'NEW DELHI-110024' 'CHENNAI- 600107' 'KERALA 683104' 'VASAI WEST.'\n",
      " 'THANE (W)' 'NEAR SANTOSH BANJARA HYDERABAD'\n",
      " 'BANASWADI (NEXT TO INDIAN BANK) BANGALORE' 'BTM BANGALORE'\n",
      " 'GREATER KAILASH 2 NEW DELHI' 'SECUNDERABAD ECIL'\n",
      " 'BANGALORE KORAMANGALA 7TH BLOCK' 'BANGALORE : 560085'\n",
      " 'GACHIBOWLI HYDERABAD'\n",
      " 'CPR LAYOUT HARLUR MAIN ROAD OPPOSITE TO OZONE EVER GREEN APARTMENT BANGALORE -'\n",
      " 'ECR NEELANKARAI CHENNAI 600115' 'WARD X11' 'PERUMBAVOOR'\n",
      " 'MIRA RAOD EAST' 'KERALA 682013' 'CHENNAI.' 'POKHRAN ROAD 2'\n",
      " 'UTTAR PRADESH' 'KARNATAKA 560102' 'MUMBAI - 400013' 'NAHARPAR'\n",
      " 'HOSUR ROAD' 'NEAR BHARAT PETROLEUM.'\n",
      " 'CHENNAI (BANG OPPOSITE INDIAN BANK)' 'SRIRAM NAGAR' 'WEST MUMBAI'\n",
      " 'VYTTILA' 'BANJARA HILLS' 'MALAPALLIPURAM P .O THRISSUR'\n",
      " 'ANDHERI WEST MUMBAI' 'KARNATAKA 560043' 'PANAMPILLY NAGAR'\n",
      " 'BORIVALI EAST.' 'ECIL' 'JUBILEE HILLS'\n",
      " 'AMRIT KAUR MARKET OPPOSITE NEW DELHI RAILWAY STATION PAHARGANJ'\n",
      " 'CHENNAI OPPOSITE 5C BUS STAND' 'TELENGANA' 'KOCHI RAVIPURAM' 'RAJANPADA'\n",
      " 'MAHABALIPURAM' 'SECUNDERABAD. WE HAVE NO BRANCHES.' 'TELANGANA 500081'\n",
      " 'GURGOAN' 'ELAMAKKARA' 'SECTOR 1' 'BANDRA W' 'KOLATHUR'\n",
      " 'CHENNAI MAHABALIPURAM' '3RD STREET' 'MUMBAI CHAKALA' 'BORIVALI WEST'\n",
      " 'RODEO DRIVE SECTOR 49' 'PALLIMUKKU' 'DELHI 110085' 'SECTOR 51'\n",
      " 'CHAMPAPET' 'ANDAVAR NAGAR' 'BANGALORE - 560103' 'KERALA 690525'\n",
      " 'OPP MUKTESHWAR ASHRAM POWAI' 'NUNGAMBAKKAM' 'BK GUDA'\n",
      " 'JOGESHWARI (W) MUMBAI' 'KUKATAPALLY' 'NEAR SECTOR 110 NOIDA' 'NAVALLUR'\n",
      " 'BESIDE EXCELLENCY GARDENS' 'MUMBAI - 80' 'BEGUMPET'\n",
      " 'MAHARAJA HOTEL BESIDE GARDANIA BAR' 'ASHOK VIHAR PHASE 1' 'TRIVANDRUM'\n",
      " 'KOCHI-18' 'NARAYANGUDA' 'THEVERA' 'CHENNAI-40' 'PALM BEACH ROAD'\n",
      " 'EAST COAST ROAD (ECR)' 'RAMAPURAM' 'CHENNAI CHROMPET' 'NANDANAM' 'SAKET'\n",
      " 'MG ROAD ERNAKULAM' 'ANDHERI LOKHANDWALA.' 'INDIRANAGAR' 'THIRUVANMIYUR'\n",
      " 'AMBATTUR' 'BANGLAORE' 'CHENNAI - 34 LANDMARK - NEAR LOYOLA COLLEGE'\n",
      " 'ANNA NAGAR WEST' 'OLD RAILWAY ROAD' 'EAST MUMBAI'\n",
      " 'KANAKAPURA ROAD BANGLORE' 'KOCHI KAKKANAD' 'KALYAN'\n",
      " 'NEAR RAMLILA GROUND' 'SERILINGAMPALLY' 'HIMAYATH NAGAR' 'NALLALA STREET'\n",
      " 'ANNA SALAI' 'OLD DELHI' 'WAGLE ESTATE' '1ST STAGE' 'KOCHI-16'\n",
      " 'KOCHI INTERNATIONAL AIRPORT VIP ROAD' 'FIRST STREET' 'CHENN AI'\n",
      " '6 & 7 - 4/64 SUBHASH NAGAR' '1ST TAVAREKERE' 'PERAMBUR'\n",
      " 'VAISHALI GHAZIABAD' 'THANISANDRA' 'BLOCK F' 'SECTOR 7 DWARKA'\n",
      " 'OPPOSITE BARATHI GAS COMPANY' 'VADAPALANI' 'KONDAPUR.' 'BADLAPUR WEST.'\n",
      " 'KALAMASSERY' 'PALAVAKKAM' 'TCS SYNERGY PARK' 'BTM 1ST STAGE'\n",
      " 'MAHADEVPURA' 'NEW BEL ROAD 560054'\n",
      " 'VELIAVEETIL HOUSE VIVEKANANDA NAGAR ELAMAKKARA' 'SHOLINGANALLUR'\n",
      " 'MAHARASHTRA 400102' 'LOWER PAREL WEST' 'TRIPUNITHURA' 'MOGAPPAIR'\n",
      " 'TELANGANA 500070' 'JP NAGAR' 'NAVI-MUMBAI' 'ASHOK NAGAR' 'MARATHAHALLI'\n",
      " 'HARIDWAR APARTMENTS' 'KERALA 682001 INDIA' 'KARNATAKA 560037'\n",
      " 'KERALA 683585' 'CHENNAI. (NEAR HOTEL MATSHYA)' 'INDIRAPURAM'\n",
      " 'BEGUMPET HYDERABAD' 'MANIKONDA'\n",
      " 'BANGALORE LAND MARK ABOVE MAHAVEER HARD WARE' 'KERALA 682304'\n",
      " 'RAJARAJESHWARI NAGAR BANGALORE' 'GST ROAD' 'FORT KOCHI'\n",
      " 'LAHARI APARTMENTS' 'RAMANTHAPUR' 'MULUND WEST' 'GURGAON HARYANA INDIA'\n",
      " 'NEW DELHI..NEAR BY SBI BANK' 'KOCHI ALUVA 102' 'PHASE 1 BANGALORE'\n",
      " 'HYDERABAD MANIKONDA'\n",
      " 'MUMBAI THIS IS A DELIVERY & TAKE-AWAY RESTAURANT ONLY.' '10TH AVENUE'\n",
      " 'UPPAL' 'NEW DELHI 110075' 'NIZAMPET' 'ULSOO' 'BANGALORE 560076'\n",
      " 'PVR PLAZA CINEMA BUILDING CONNAUGHT PLACE' 'GURGAON HARYANA' 'CHROMEPET'\n",
      " 'KERALA 682024' 'JANAKPURI' 'SECUNDERABAD.'\n",
      " 'B.B.M.P EAST (KARNATAKA) - 560049' 'TAMBARAM' 'MALLESHWARAM BANGALORE'\n",
      " 'VADAPALANI.' 'DIST. CENTER NEW DELHI' 'BANGALORE ROAD' 'KOCHI.'\n",
      " 'THANE MUMBAI' 'KADUBESANAHALLI BANGALORE' 'VASAI WEST'\n",
      " 'MIG HOUSING SOCIETY' 'HARYANA' 'BORIVALI WEST.' 'GOLF COURSE ROAD'\n",
      " 'KHAR MUMBAI' 'NEAR JYOTHINIVAS COLLEGE' 'ANNA NAGAR EAST' 'MASAB TANK'\n",
      " 'VASAI MUMBAI' 'PANATHUR MAIN ROAD' 'NEAR ANDHERI WEST STATION'\n",
      " 'OPPOSITE TO WESTERN SIDE OF ITPL SERVICE GATE' 'KALKAJI' 'APR CHAMBERS'\n",
      " 'TAMIL NADU 600102' 'MAHARASHTRA.' 'GANDHINAGAR RD'\n",
      " 'NEAR ANDHERI EAST STATION' 'WHITEFIELD' 'KERALA 682036'\n",
      " 'MIRA ROAD THANE MUMBAI' 'INDIA GATE NEW DELHI' 'BANGALORE - 560095'\n",
      " 'SHOLINGANALLUR. CHENNAI' 'CHENNAI (ABOVE BOMBAY BRASSERIE)' 'CHENNAI 37'\n",
      " '682024' 'GIRGAUM' 'GREATER KAILASH 1 (GK 1) NEW DELHI' 'KURLA (W)'\n",
      " 'MUMBAI 400015' 'THANE WEST THANE WEST' 'KOCHI PANAMPILLY NAGAR' 'MARAD'\n",
      " 'MAHARASHTRA 400092' 'NEAR SECTOR 34' 'MEHDIPATNAM HYDERABAD'\n",
      " 'NALLAGANDLA' 'VANDALUR' 'CHENNAI 40' 'SECUNDERBAD' 'MM NAGAR'\n",
      " 'MUMBAI 400070' 'CHITTETHUKKARA' 'BTM' 'DOMBIVLI' 'SAHAKARA NAGAR'\n",
      " 'MOHAMMAD ALI ROAD MUMBAI' 'CHENNAI 600040' 'TAVAREKERE MAIN ROAD'\n",
      " 'COMMUNITY CENTRE' 'KERALA 682022' 'DELH.' 'SECTOR-6 NOIDA 201301'\n",
      " 'KAARAIKUDI COMPLEX' 'THIRUVANMIYUR (OPP EUROKIDS LB ROAD)'\n",
      " 'VIRAR MUMBAI' 'TOLICHOWKI' 'HYDERABA' 'KERALA 682305' 'ALWARPET'\n",
      " 'KERALA 682015' 'MUMBAI VEERA DESAI AREA' 'KERALA 682018' 'KERALA 682028'\n",
      " 'SURARAM' 'CHENNAI VELACHERY'\n",
      " 'FORUM SUJANA MALL OPPOSITE TO MALAYSIAN TOWNSHIP' 'OLD HAFEEZPET'\n",
      " 'YOUSUFGUDA' 'CHENNAI-600008' 'MUMBAI ULHASNAGAR'\n",
      " 'JOGESHWARI WEST MUMBAI' 'CHEPAUK' 'CHOWPATTY' 'CHURCH STREET'\n",
      " 'BALAVINAYAGAR NAGAR CHENNAI' 'T-NAGAR CHENNAI' 'RA PURAM'\n",
      " 'HYDERABAD.STAR HYPERMARKET OPPOSITE SIDE SERVICE ROAD'\n",
      " 'CHENNAI INJAMBAKKAM' 'MUMBAI MUMBRA' 'HABSIGUDA' 'KURLA MUMBAI'\n",
      " 'TELANGANA 500027' 'CHENNA' 'KERALA 682021' 'KANDIVALI WEST'\n",
      " 'CHENNAI-119' 'NOIDA EXTENTION' 'SHIHAB THANGAL ROAD' 'NEW DELHI 110011'\n",
      " 'MIUMBAI' 'BORIVALI (W) MUMBAI: 400 092.' 'VANASTHALIPURAM' 'KK ROAD'\n",
      " 'CHENNAI - 600018' 'OPPOSITE ELLORA BUILDING']\n",
      "\n",
      "\n",
      "Number of Unique LOCALITY :  1611\n",
      "\n",
      "\n",
      "Unique LOCALITY:\n",
      " ['DOMBIVALI EAST' 'RAMAPURAM' 'SALIGRAMAM' ... 'OFF CARTER ROAD'\n",
      " 'SRM BACK GATE' 'PERRY CROSS ROAD']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "# Data Analysisng\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "#Combining trainig set and test sets for analysing data and finding patterns\n",
    "\n",
    "data_temp = [training_data[['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY','RATING', 'VOTES']],\n",
    "             test_data]\n",
    "data_temp = pd.concat(data_temp)\n",
    "\n",
    "# Analysing TITLE \n",
    "new_df = data_temp['TITLE'].str.split(',',expand=True)\n",
    "data_temp['TITLE'] = pd.concat([new_df[[0]], new_df[1]], axis=1)\n",
    "data_temp['TITLE'] = data_temp['TITLE'].str.upper()\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(data_temp['TITLE']).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(data_temp['TITLE']).unique())\n",
    "all_titles = list(pd.Series(data_temp['TITLE']).unique())\n",
    "all_titles.append('NONE')\n",
    "\n",
    "\n",
    "# Analysing CUISINES\n",
    "new_df1 = data_temp['CUISINES'].str.split(',',expand=True)\n",
    "data_temp['CUISINES'] = pd.concat([new_df1[[0]], new_df1[1], new_df1[3], new_df1[4], new_df1[5], new_df1[6],\n",
    "                                   new_df1[7]],axis=1)\n",
    "data_temp['CUISINES'] = data_temp['CUISINES'].str.upper()\n",
    "\n",
    "print(\"\\n\\nNumber of Unique CUISINES : \", len(pd.Series(data_temp['CUISINES']).unique()))\n",
    "print(\"\\n\\nUnique CUISINES:\\n\", pd.Series(data_temp['CUISINES']).unique())\n",
    "all_cuisines = list(pd.Series(data_temp['CUISINES']).unique())\n",
    "\n",
    "# Analysing CITY\n",
    "data_temp['CITY'] = data_temp['CITY'].str.upper()\n",
    "\n",
    "print(\"\\n\\nNumber of Unique CITY : \", len(pd.Series(data_temp['CITY']).unique()))\n",
    "print(\"\\n\\nUnique CITY:\\n\", pd.Series(data_temp['CITY']).unique())\n",
    "all_cities = list(pd.Series(data_temp['CITY']).unique())\n",
    "\n",
    "# Analysing LOCALITY\n",
    "data_temp['LOCALITY'] = data_temp['LOCALITY'].str.upper()\n",
    "\n",
    "print(\"\\n\\nNumber of Unique LOCALITY : \", len(pd.Series(data_temp['LOCALITY']).unique()))\n",
    "print(\"\\n\\nUnique LOCALITY:\\n\", pd.Series(data_temp['LOCALITY']).unique())\n",
    "\n",
    "all_localities = pd.Series(data_temp['LOCALITY']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "# Cleaning Training Set\n",
    "#______________________\n",
    "\n",
    "# TITLE - 2 titels\n",
    "\n",
    "new_df_1 = training_data['TITLE'].str.split(',',expand=True)\n",
    "training_data['TITLE1'] = new_df_1[0].str.upper()\n",
    "training_data['TITLE2'] = new_df_1[1].str.upper()\n",
    "training_data['TITLE2'] = training_data['TITLE2'].str.replace('None','NONE')\n",
    "\n",
    "#Cleaning CUISINES \n",
    "new_df_2 = training_data['CUISINES'].str.split(',',expand=True)\n",
    "training_data['CUISINE1'] = new_df_2[0].str.upper()\n",
    "training_data['CUISINE2'] = new_df_2[1].str.upper()\n",
    "training_data['CUISINE3'] = new_df_2[2].str.upper()\n",
    "training_data['CUISINE4'] = new_df_2[3].str.upper()\n",
    "training_data['CUISINE5'] = new_df_2[4].str.upper()\n",
    "training_data['CUISINE6'] = new_df_2[5].str.upper()\n",
    "training_data['CUISINE7'] = new_df_2[6].str.upper()\n",
    "training_data['CUISINE8'] = new_df_2[7].str.upper()\n",
    "all_cuisines.append('None')\n",
    "\n",
    "# Cleaning CITY\n",
    "training_data['CITY'] = training_data['CITY'].str.upper()\n",
    "training_data['CITY'].fillna('NOT AVAILABLE',inplace=True)\n",
    "\n",
    "# Cleaning LOCALITY\n",
    "training_data['LOCALITY'] = training_data['LOCALITY'].str.upper()\n",
    "training_data['LOCALITY'].fillna('NOT AVAILABLE',inplace=True)\n",
    "\n",
    "#Cleaning Rating\n",
    "# training_data.dtypes\n",
    "training_data['RATING'] = training_data['RATING'].str.replace('-','')\n",
    "training_data['RATING'] = training_data['RATING'].str.replace('NEW','')\n",
    "training_data['RATING'].fillna(0,inplace=True)\n",
    "training_data['RATING'] = pd.to_numeric(training_data['RATING'])\n",
    "\n",
    "# Votes\n",
    "training_data['VOTES'].fillna('0 votes',inplace = True)\n",
    "training_data['VOTES'] = training_data['VOTES'].str.replace('votes','')\n",
    "training_data['VOTES'] = pd.to_numeric(training_data['VOTES'])\n",
    "\n",
    "\n",
    "new_data_train = {}\n",
    "\n",
    "new_data_train['TITLE1'] = training_data['TITLE1']\n",
    "new_data_train['TITLE2'] = training_data['TITLE2']\n",
    "new_data_train['RESTAURANT_ID'] = training_data[\"RESTAURANT_ID\"]\n",
    "new_data_train['CUISINE1'] = training_data['CUISINE1']\n",
    "new_data_train['CUISINE2'] = training_data['CUISINE2']\n",
    "new_data_train['CUISINE3'] = training_data['CUISINE3']\n",
    "new_data_train['CUISINE4'] = training_data['CUISINE4']\n",
    "new_data_train['CUISINE5'] = training_data['CUISINE5']\n",
    "new_data_train['CUISINE6'] = training_data['CUISINE6']\n",
    "new_data_train['CUISINE7'] = training_data['CUISINE7']\n",
    "new_data_train['CUISINE8'] = training_data['CUISINE8']\n",
    "new_data_train['CITY'] = training_data['CITY']\n",
    "new_data_train['LOCALITY'] = training_data['LOCALITY']\n",
    "new_data_train['RATING'] = training_data['RATING']\n",
    "new_data_train['VOTES'] = training_data['VOTES']\n",
    "new_data_train['COST'] = training_data[\"COST\"]\n",
    "\n",
    "new_data_train = pd.DataFrame(new_data_train)\n",
    "new_data_train.head()\n",
    "\n",
    "\n",
    "# Cleaning Test Set\n",
    "#______________________\n",
    "\n",
    "# TITLE - 2 titels\n",
    "\n",
    "new_df_3 = test_data['TITLE'].str.split(',',expand=True)\n",
    "test_data['TITLE1'] = new_df_3[0].str.upper()\n",
    "test_data['TITLE2'] = new_df_3[1].str.upper()\n",
    "test_data['TITLE2'] = test_data['TITLE2'].str.replace('None','NONE')\n",
    "#Cleaning CUISINES \n",
    "new_df_4 = test_data['CUISINES'].str.split(',',expand=True)\n",
    "test_data['CUISINE1'] = new_df_4[0].str.upper()\n",
    "test_data['CUISINE2'] = new_df_4[1].str.upper()\n",
    "test_data['CUISINE3'] = new_df_4[2].str.upper()\n",
    "test_data['CUISINE4'] = new_df_4[3].str.upper()\n",
    "test_data['CUISINE5'] = new_df_4[4].str.upper()\n",
    "test_data['CUISINE6'] = new_df_4[5].str.upper()\n",
    "test_data['CUISINE7'] = new_df_4[6].str.upper()\n",
    "test_data['CUISINE8'] = new_df_4[7].str.upper()\n",
    "\n",
    "# Cleaning CITY\n",
    "test_data['CITY'] = test_data['CITY'].str.upper()\n",
    "test_data['CITY'].fillna('NOT AVAILABLE',inplace=True)\n",
    "\n",
    "# Cleaning LOCALITY\n",
    "test_data['LOCALITY'] = test_data['LOCALITY'].str.upper()\n",
    "test_data['LOCALITY'].fillna('NOT AVAILABLE',inplace=True)\n",
    "\n",
    "#Cleaning Rating\n",
    "# training_data.dtypes\n",
    "test_data['RATING'] = test_data['RATING'].str.replace('-','')\n",
    "test_data['RATING'] = test_data['RATING'].str.replace('NEW','')\n",
    "test_data['RATING'].fillna(0,inplace=True)\n",
    "test_data['RATING'] = pd.to_numeric(test_data['RATING'])\n",
    "\n",
    "# Votes\n",
    "test_data['VOTES'].fillna('0 votes',inplace = True)\n",
    "test_data['VOTES'] = test_data['VOTES'].str.replace('votes','')\n",
    "test_data['VOTES'] = pd.to_numeric(test_data['VOTES'])\n",
    "\n",
    "\n",
    "new_data_test = {}\n",
    "\n",
    "new_data_test['TITLE1'] = test_data['TITLE1']\n",
    "new_data_test['TITLE2'] = test_data['TITLE2']\n",
    "new_data_test['RESTAURANT_ID'] = test_data[\"RESTAURANT_ID\"]\n",
    "new_data_test['CUISINE1'] = test_data['CUISINE1']\n",
    "new_data_test['CUISINE2'] = test_data['CUISINE2']\n",
    "new_data_test['CUISINE3'] = test_data['CUISINE3']\n",
    "new_data_test['CUISINE4'] = test_data['CUISINE4']\n",
    "new_data_test['CUISINE5'] = test_data['CUISINE5']\n",
    "new_data_test['CUISINE6'] = test_data['CUISINE6']\n",
    "new_data_test['CUISINE7'] = test_data['CUISINE7']\n",
    "new_data_test['CUISINE8'] = test_data['CUISINE8']\n",
    "new_data_test['CITY'] = test_data['CITY']\n",
    "new_data_test['LOCALITY'] = test_data['LOCALITY']\n",
    "new_data_test['RATING'] = test_data['RATING']\n",
    "new_data_test['VOTES'] = test_data['VOTES']\n",
    "new_data_test['COST'] = test_data[\"COST\"]\n",
    "\n",
    "new_data_test = pd.DataFrame(new_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morning_data_train():\n",
    "    new_data_train.loc[:, ('MORNING')]=0\n",
    "    for index,val in enumerate(training_data.loc[:,('TIME')]):\n",
    "        if any(s in val for s in ['am', 'AM', 'Am', '24']):\n",
    "            new_data_train.loc[index, 'MORNING'] = 1\n",
    "\n",
    "def evening_data_train():\n",
    "    new_data_train.loc[:, ('EVENING')] = 0\n",
    "    for index, val in enumerate(training_data.loc[:, ('TIME')][:6]):\n",
    "        if any(s in val for s in ['pm', 'PM' , 'Pm' , 'noon', '24']):\n",
    "            new_data_train.loc[index, 'EVENING'] = 1\n",
    "\n",
    "\n",
    "morning_data_train()\n",
    "evening_data_train()\n",
    "\n",
    "\n",
    "def morning_data_test():\n",
    "    new_data_test.loc[:, ('MORNING')]=0\n",
    "    for index,val in enumerate(test_data.loc[:,('TIME')]):\n",
    "        if any(s in val for s in ['am', 'AM', 'Am', '24']):\n",
    "            new_data_test.loc[index, 'MORNING'] = 1\n",
    "\n",
    "def evening_data_test():\n",
    "    new_data_test.loc[:, ('EVENING')] = 0\n",
    "    for index, val in enumerate(test_data.loc[:, ('TIME')][:6]):\n",
    "        if any(s in val for s in ['pm', 'PM' , 'Pm' , 'noon', '24']):\n",
    "            new_data_test.loc[index, 'EVENING'] = 1\n",
    "            \n",
    "morning_data_test()\n",
    "evening_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1         BAR\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "12685    None\n",
       "12686     BAR\n",
       "12687    None\n",
       "12688    None\n",
       "12689    None\n",
       "Name: TITLE2, Length: 12690, dtype: object"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_data_train['TITLE2'].str.replace('None','NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Variables\n",
    "#_______________________________\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-387-6fb2a8a8deff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Training Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnew_data_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mnew_data_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 49\u001b[0;31m                              % str(diff))\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]"
     ]
    }
   ],
   "source": [
    "le_titles = LabelEncoder()\n",
    "le_cuisines = LabelEncoder()\n",
    "\n",
    "le_city = LabelEncoder()\n",
    "\n",
    "le_locality = LabelEncoder()\n",
    "\n",
    "le_titles.fit(all_titles)\n",
    "le_cuisines.fit(all_cuisines)\n",
    "\n",
    "le_city.fit(all_cities)\n",
    "# le_locality.fit(all_localities)\n",
    "new_data_train.TITLE2.fillna(value=pd.np.nan, inplace=True)\n",
    "print(new_data_train['TITLE2'][0])\n",
    "\n",
    "# Training Set  \n",
    "new_data_train['TITLE1'] = le_titles.transform(new_data_train['TITLE1'])\n",
    "new_data_train['TITLE2'] = le_titles.transform(new_data_train['TITLE2'])\n",
    "\n",
    "\n",
    "# new_data_train['CUISINE1'] = le_cuisines.transform(new_data_train['CUISINE1'])\n",
    "# new_data_train['CUISINE2'] = le_cuisines.transform(new_data_train['CUISINE2'])\n",
    "# new_data_train['CUISINE3'] = le_cuisines.transform(new_data_train['CUISINE3'])\n",
    "# new_data_train['CUISINE4'] = le_cuisines.transform(new_data_train['CUISINE4'])\n",
    "# new_data_train['CUISINE5'] = le_cuisines.transform(new_data_train['CUISINE5'])\n",
    "# new_data_train['CUISINE6'] = le_cuisines.transform(new_data_train['CUISINE6'])\n",
    "# new_data_train['CUISINE7'] = le_cuisines.transform(new_data_train['CUISINE7'])\n",
    "# new_data_train['CUISINE8'] = le_cuisines.transform(new_data_train['CUISINE8'])\n",
    "\n",
    "\n",
    "# new_data_train['CITY'] = le_city.transform(new_data_train['CITY'])\n",
    "# new_data_train['LOCALITY'] = le_locality.transform(new_data_train['LOCALITY'])\n",
    "\n",
    "# # Test Set\n",
    "\n",
    "# new_data_test['TITLE1'] = le_titles.transform(new_data_test['TITLE1'])\n",
    "# new_data_test['TITLE2'] = le_titles.transform(new_data_test['TITLE2'])\n",
    "\n",
    "\n",
    "# new_data_test['CUISINE1'] = le_cuisines.transform(new_data_test['CUISINE1'])\n",
    "# new_data_test['CUISINE2'] = le_cuisines.transform(new_data_test['CUISINE2'])\n",
    "# new_data_test['CUISINE3'] = le_cuisines.transform(new_data_test['CUISINE3'])\n",
    "# new_data_test['CUISINE4'] = le_cuisines.transform(new_data_test['CUISINE4'])\n",
    "# new_data_test['CUISINE5'] = le_cuisines.transform(new_data_test['CUISINE5'])\n",
    "# new_data_test['CUISINE6'] = le_cuisines.transform(new_data_test['CUISINE6'])\n",
    "# new_data_test['CUISINE7'] = le_cuisines.transform(new_data_test['CUISINE7'])\n",
    "# new_data_test['CUISINE8'] = le_cuisines.transform(new_data_test['CUISINE8'])\n",
    "\n",
    "\n",
    "# new_data_test['CITY'] = le_city.transform(new_data_test['CITY'])\n",
    "# new_data_test['LOCALITY'] = le_locality.transform(new_data_test['LOCALITY'])\n",
    "\n",
    "\n",
    "# # Classifying Independent and Dependent Features\n",
    "# #_______________________________________________\n",
    "\n",
    "# # Dependent Variable\n",
    "# Y_train = new_data_train.iloc[:, -1].values  \n",
    "\n",
    "# # Independent Variables\n",
    "# X_train = new_data_train.iloc[:,0 : -1].values\n",
    "\n",
    "# # Independent Variables for Test Set\n",
    "# X_test = new_data_test.iloc[:,:].values\n",
    "\n",
    "\n",
    "# # Feature Scaling\n",
    "# #________________\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc = StandardScaler()\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Y_train = Y_train.reshape((len(Y_train), 1)) \n",
    "\n",
    "# Y_train = sc.fit_transform(Y_train)\n",
    "\n",
    "# Y_train = Y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
